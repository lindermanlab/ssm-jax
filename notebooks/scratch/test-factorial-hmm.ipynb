{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as np\n",
    "import jax.random as jr\n",
    "import jax.scipy.special as spsp\n",
    "from jax import value_and_grad, vmap\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from ssm.factorial_hmm.posterior import _factorial_hmm_log_normalizer\n",
    "from ssm.hmm.posterior import hmm_log_normalizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try constructing a factorial HMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ssm.factorial_hmm.models import NormalFactorialHMM\n",
    "\n",
    "num_states = (2, 2, 2)\n",
    "factorial_hmm = NormalFactorialHMM(num_states=num_states, seed=jr.PRNGKey(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states, data = factorial_hmm.sample(jr.PRNGKey(0), 10000)\n",
    "\n",
    "# Plot the states and data\n",
    "fig, axs = plt.subplots(len(num_states) + 1, 1, figsize=(8, 6), sharex=True)\n",
    "for i in range(len(num_states)):\n",
    "    axs[i].imshow(states[i][None, :], cmap=\"Greys\", aspect=\"auto\")\n",
    "    axs[i].set_ylabel(\"State {}\".format(i))\n",
    "    axs[i].set_yticks([])\n",
    "axs[-1].plot(data)\n",
    "axs[-1].set_ylabel(\"Data\")\n",
    "axs[-1].set_xlabel(\"Time\")\n",
    "axs[-1].set_xlim(0, 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct another factorial HMM and try to fit it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_factorial_hmm = NormalFactorialHMM(num_states, seed=jr.PRNGKey(1))\n",
    "lps, _, posteriors = test_factorial_hmm.fit(data, tol=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(lps)\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"log probability\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute marginal probabilities for each state\n",
    "expected_states = posteriors.expected_states[0]\n",
    "marginals = []\n",
    "for j in range(len(num_states)):\n",
    "    axes = tuple(np.concatenate([np.arange(j), np.arange(j+1, len(num_states))]) + 1)\n",
    "    marginals.append(np.sum(expected_states, axis=axes))\n",
    "\n",
    "# Plot the states and data\n",
    "fig, axs = plt.subplots(len(num_states) + 1, 1, figsize=(8, 6), sharex=True)\n",
    "for i in range(len(num_states)):\n",
    "    axs[i].imshow(marginals[i][None, :, 1], cmap=\"Greys\", aspect=\"auto\", vmin=0, vmax=1)\n",
    "    axs[i].set_ylabel(\"State {}\".format(i))\n",
    "    axs[i].set_yticks([])\n",
    "    \n",
    "axs[-1].plot(data)\n",
    "axs[-1].set_ylabel(\"Data\")\n",
    "axs[-1].set_xlabel(\"Time\")\n",
    "axs[-1].set_xlim(0, 200)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = np.sum(posteriors.expected_states[0] * test_factorial_hmm._emissions._distribution.loc, \n",
    "              axis=tuple(1 + np.arange(len(num_states))))\n",
    "\n",
    "plt.plot(data)\n",
    "plt.plot(yhat)\n",
    "plt.xlim(0, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(factorial_hmm._emissions._distribution.variance())\n",
    "factorial_hmm._emissions._distribution.loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(test_factorial_hmm._emissions._distribution.variance())\n",
    "test_factorial_hmm._emissions._distribution.loc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = jr.PRNGKey(0)\n",
    "num_states = (3, 4)\n",
    "num_timesteps = 10\n",
    "\n",
    "log_initial_state_probs = np.zeros(num_states)\n",
    "log_transition_matrices = tuple(\n",
    "    jr.normal(key, (k, k)) for key, k in zip(jr.split(rng, len(num_states)), num_states))\n",
    "log_transition_matrices = tuple(\n",
    "    x - spsp.logsumexp(x, axis=1, keepdims=True)\n",
    "    for x in log_transition_matrices\n",
    ")\n",
    "\n",
    "rng, this_rng = jr.split(rng, 2)\n",
    "log_likelihoods = jr.normal(this_rng, (num_timesteps,) + num_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_normalizer, filtered_potentials = \\\n",
    "    _factorial_hmm_log_normalizer(log_initial_state_probs,\n",
    "                                  log_transition_matrices,\n",
    "                                  log_likelihoods)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_transition_matrix = np.kron(\n",
    "    np.exp(log_transition_matrices[0]),\n",
    "    np.exp(log_transition_matrices[1]),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_normalizer2, filtered_potentials2 = \\\n",
    "    hmm_log_normalizer(log_initial_state_probs.reshape(-1),\n",
    "                       np.log(big_transition_matrix),\n",
    "                       log_likelihoods.reshape(num_timesteps, -1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_normalizer, log_normalizer2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.allclose(filtered_potentials.reshape(num_timesteps, -1), filtered_potentials2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _factorial_hmm_log_normalizer(log_initial_state_probs,\n",
    "#                                   log_transition_matrices,\n",
    "#                                   log_likelihoods)\n",
    "\n",
    "f = value_and_grad(_factorial_hmm_log_normalizer, argnums=(1, 2), has_aux=True)\n",
    "(log_normalizer, filtered_potentials), (expected_transitions, expected_states) = \\\n",
    "    f(log_initial_state_probs, log_transition_matrices, log_likelihoods)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Joint distribution for the transitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow_probability.substrates import jax as tfp\n",
    "tfd = tfp.distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In TFP, we can write this as:\n",
    "prev_states = tuple(1 for _ in num_states)\n",
    "\n",
    "Root = tfd.JointDistributionCoroutine.Root  # Convenient alias.\n",
    "def model():\n",
    "    for prev_state, log_transition_matrix in zip(prev_states, log_transition_matrices):\n",
    "        yield Root(tfd.Categorical(logits=log_transition_matrix[prev_state]))\n",
    "        \n",
    "joint = tfd.JointDistributionCoroutine(model)\n",
    "next_states = tuple(joint.sample(seed=jr.PRNGKey(1), sample_shape=(100,)))\n",
    "joint.log_prob(next_states)\n",
    "# next_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = np.arange(12).astype(np.float32).reshape(num_states)\n",
    "scales = np.ones(num_states)\n",
    "\n",
    "dist = tfd.Normal(means, scales)\n",
    "\n",
    "state = (0, 0)\n",
    "\n",
    "dist[state].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = jr.normal(jr.PRNGKey(0), (100,))\n",
    "lps = vmap(dist.log_prob)(data)\n",
    "lps.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%debug"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1c9b7abd99f812592e04518a2dddca5f7bc8ca20b74b8ad7e1b8422bf8e8c0a8"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit ('ssm_jax': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
