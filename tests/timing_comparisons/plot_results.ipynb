{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "935b7eaf",
   "metadata": {},
   "source": [
    "# Notebook to Generate Benchmark Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22f7e60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import glob\n",
    "\n",
    "plt.style.use(\"ggplot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43a8ff26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_json_results_to_df(json_results_fname):\n",
    "\n",
    "    # read in json from fname\n",
    "    with open(json_results_fname, \"r\") as f:\n",
    "        json_data = json.load(f)\n",
    "\n",
    "    # construct dataframe\n",
    "    df = pd.DataFrame(json_data[\"benchmarks\"])\n",
    "    df = pd.concat([df, df[\"stats\"].apply(pd.Series)], axis=1)\n",
    "    df[\"test_name\"] = df[\"name\"].apply(lambda x: x.split(\"[\")[0])\n",
    "    df[\"param_name\"] = df[\"params\"].apply(lambda x: list(x.keys())[0])\n",
    "    df[\"param_value\"] = df[\"params\"].apply(lambda x: list(x.values())[0])\n",
    "\n",
    "    # select columns to keep\n",
    "    columns = [\n",
    "        \"test_name\",\n",
    "        \"param_name\",\n",
    "        \"param_value\",\n",
    "        \"min\",\n",
    "        \"max\",\n",
    "        \"mean\",\n",
    "        \"median\",\n",
    "        \"stddev\",\n",
    "        \"ops\",\n",
    "        \"iterations\",\n",
    "        \"rounds\",\n",
    "        \"extra_info\",\n",
    "        \"params\",\n",
    "    ]\n",
    "    df = df[columns]\n",
    "    return df\n",
    "\n",
    "\n",
    "def plot_series(x, y, color=\"C0\", label=\"\"):\n",
    "    params = np.array(x)\n",
    "    mean_times = np.array(y)\n",
    "    isnan = np.isnan(mean_times)\n",
    "    if np.sum(~isnan) > 1:\n",
    "        m, b = np.polyfit(params[~isnan], mean_times[~isnan], deg=1)\n",
    "        plt.plot(params, m * params + b, \"--\", color=color, label=label)\n",
    "    else:\n",
    "        m = 0\n",
    "        b = mean_times[~isnan]\n",
    "        plt.plot([], [], \"--\", color=color, label=label)\n",
    "    ys = np.copy(mean_times)\n",
    "    ys[isnan] = m * params[isnan] + b  # replace nans with linear prediction\n",
    "    for x, y, isna in zip(params, ys, isnan):\n",
    "        plt.scatter(\n",
    "            x, y, marker=\"x\" if isna else \"o\", s=80 if isna else 40, color=color\n",
    "        )\n",
    "\n",
    "\n",
    "def load_multiple_runs(benchmark_runs):\n",
    "    runs = []\n",
    "    for run_name, run_fname in benchmark_runs.items():\n",
    "        df = parse_json_results_to_df(run_fname)\n",
    "        cols = df.columns\n",
    "        cols = cols.insert(0, \"run_name\")\n",
    "        df[\"run_name\"] = run_name\n",
    "        df = df[cols]\n",
    "        runs.append(df)\n",
    "    df = pd.concat(runs)\n",
    "    return df\n",
    "\n",
    "\n",
    "def plot_across_params(runs_df, show_plots=False, save_to_pdf: bool or str = False):\n",
    "    colors = [plt.cm.tab20(i) for i in range(20)]\n",
    "    if save_to_pdf:\n",
    "        pdf = PdfPages(save_to_pdf)\n",
    "    for test_name, test_grp in runs_df.groupby([\"test_name\"]):\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        # plot time vs. params for different runs (as different series)\n",
    "        for i, (run_name, run_grp) in enumerate(test_grp.groupby([\"run_name\"])):\n",
    "            plot_series(\n",
    "                run_grp[\"param_value\"], run_grp[\"mean\"], label=run_name, color=colors[i % len(colors)]\n",
    "            )\n",
    "        plt.title(test_name)\n",
    "        plt.xlabel(run_grp[\"param_name\"].iloc[0])\n",
    "        plt.ylabel(\"time (s)\")\n",
    "        ax = plt.gca()\n",
    "        box = ax.get_position()  # Shink current axis by 20% to fit legend in pdf\n",
    "        ax.set_position([box.x0, box.y0, box.width * 0.8, box.height])\n",
    "        plt.legend(bbox_to_anchor=(1, 1))\n",
    "        if save_to_pdf:\n",
    "            pdf.savefig()\n",
    "        if show_plots:\n",
    "            plt.show()\n",
    "        plt.close()\n",
    "    if save_to_pdf:\n",
    "        pdf.close()\n",
    "\n",
    "\n",
    "def plot_across_runs(runs_df, show_plots=False, save_to_pdf: bool or str = False):\n",
    "    colors = [plt.cm.tab20(i) for i in range(20)]\n",
    "    if save_to_pdf:\n",
    "        pdf = PdfPages(save_to_pdf)\n",
    "    for i, (test_name, test_grp) in enumerate(runs_df.groupby([\"test_name\"])):\n",
    "        for param_value, param_grp in test_grp.groupby([\"param_value\"]):\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            run_names = param_grp[\"run_name\"][::-1]\n",
    "            height = np.nan_to_num(np.array(param_grp[\"mean\"]), -1)[::-1]\n",
    "            plt.bar(x=run_names, height=height, label=param_grp, color=colors)\n",
    "            plt.title(f\"{test_name} [{param_value}]\")\n",
    "            plt.xticks(rotation=45)\n",
    "            plt.ylabel(\"time (s)\")\n",
    "            ax = plt.gca()\n",
    "            box = ax.get_position()  # Shink current axis by 20% to fit xlabels in pdf\n",
    "            ax.set_position([box.x0, box.y0 + (box.height * 0.2), box.width, box.height * 0.8])\n",
    "            if save_to_pdf:\n",
    "                pdf.savefig()\n",
    "            if show_plots:\n",
    "                plt.show()\n",
    "            plt.close()\n",
    "    if save_to_pdf:\n",
    "        pdf.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "fnames = sorted(glob.glob(\"./.benchmarks/Linux-CPython-3.9-64bit/*\"))\n",
    "benchmark_runs = {fname.split(\"/\")[-1].split(\"_\")[0]: fname for fname in fnames}\n",
    "benchmark_runs[\"ssm_v0\"] = benchmark_runs[\"ssm_v0\"] = \"/Users/collinschlager/Code/ssm-jax-refactor/tests/timing_comparisons/ssm_v0_benchmark_tests/.benchmarks/Linux-CPython-3.9-64bit/0001_a8209a16cd8bed2af0f268430f5b3c0523c0a097_20211026_203852.json\"\n",
    "\n",
    "benchmark_runs = {\n",
    "    'ssm_v0': './ssm_v0_benchmark_tests/.benchmarks/Linux-CPython-3.9-64bit/0002_0e8715d42a296f7b173f266ea77d0732a5856292_20211030_234215.json',\n",
    "    '0001': './.benchmarks/Linux-CPython-3.9-64bit/0001_b1e3bd354ba2d60c22df414fdc5a818ea4a43276_20211026_075238.json',\n",
    "    '0002': './.benchmarks/Linux-CPython-3.9-64bit/0002_a8209a16cd8bed2af0f268430f5b3c0523c0a097_20211026_194515.json',\n",
    "    '0003': './.benchmarks/Linux-CPython-3.9-64bit/0003_scott_refactor_hmm.json',\n",
    "    '0004': './.benchmarks/Linux-CPython-3.9-64bit/0004_e0c4d645e77ff2c96618198873bf9a50b92b7c55_20211028_183653.json',\n",
    "    '0005': './.benchmarks/Linux-CPython-3.9-64bit/0005_scott_refactor.json',\n",
    "    '0006': './.benchmarks/Linux-CPython-3.9-64bit/0006_bd0a4ba326ac842a32b45e79cba92d1a7f29cd18_20211030_225949.json',\n",
    "}\n",
    "\n",
    "runs_df = load_multiple_runs(benchmark_runs)\n",
    "plot_across_params(runs_df, save_to_pdf=\"timing_report_A.pdf\")\n",
    "plot_across_runs(runs_df, save_to_pdf=\"timing_report_B.pdf\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b6376f36d2a576cb3aa96bdc8604fd3c48ab4175c4f0714c2dd2fe4ec268050b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('ssmjax': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
